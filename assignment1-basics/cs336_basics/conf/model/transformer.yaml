_target_: utils.Transformer
vocab_size: 10_000
d_model: 512
num_heads: 16
d_ff: 1344
rope_theta: 10_000
context_length: 256
num_layers: 4
device: cuda
